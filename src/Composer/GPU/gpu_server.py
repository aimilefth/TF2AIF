"""
Author: Aimilios Leftheriotis
Affiliations: Microlab@NTUA, VLSILab@UPatras

This module defines the GpuServer class, which inherits from the BaseExperimentServer class defined in the experiment_server module.
The GpuServer class represents a GPU-based implementation of the experiment server, optimized for running ONNX Runtime models.

Overview:
- The GpuServer class is responsible for initializing the ONNX Runtime environment, loading the model, and executing inference experiments.
- It includes methods for single and multiple inference runs, warm-up routines, and platform-specific preprocessing and postprocessing.

Classes:
- GpuServer: Inherits from BaseExperimentServer and implements GPU-specific initialization and inference methods.

Methods:
- __init__(self, logger): Initializes the GpuServer instance, sets up the logger, initializes the kernel, and performs a warm-up run.
- init_kernel(self): Sets up the ONNX Runtime inference session, configures execution providers, and loads the model.
- warm_up(self): Performs a warm-up run by passing a dummy input through the ONNX Runtime session.
- experiment_single(self, input, run_total=1): Executes a single experiment, taking a numpy array as input and returning a numpy array as output.
- experiment_multiple(self, dataset, run_total): Executes multiple experiments, taking a tf.data.Dataset as input and returning a numpy array as output.
- platform_preprocess(self, data): Placeholder for AI-framework/platform pair-specific preprocessing.
- platform_postprocess(self, data): Placeholder for AI-framework/platform pair-specific postprocessing.

DO NOT edit this file directly.
"""

import os
import time
import numpy as np
import tensorflow as tf
import onnxruntime as ort
import experiment_server

class GpuServer(experiment_server.BaseExperimentServer):
    """
    GPU-specific server implementation for running ONNX Runtime models.
    Inherits from BaseExperimentServer and implements GPU-specific initialization and inference methods.
    """
    def __init__(self, logger):
        """Initialize the GpuServer instance, set up the logger, initialize the kernel, and perform a warm-up run."""
        super().__init__(logger)
        self.sess = None
        self.server_configs['PRECISION'] = os.environ['PRECISION']
        self.server_configs['CALIBRATION'] = os.environ['CALIBRATION']
        self.server_configs['providers'] = None
        self.server_configs['input_name'] = None
        self.init_kernel()
        self.warm_up()
    
    def init_kernel(self):
        """
        Initialize one-time AI-framework/platform pair-specific server operations.
        Sets up the ONNX Runtime inference session, loads the model, and configures execution providers.
        """
        start = time.perf_counter()

        # Define providers and their configurations for ONNX Runtime
        precision = self.server_configs['PRECISION'].lower()
        if precision == 'fp32':
            self.server_configs['providers'] = [
                ('TensorrtExecutionProvider', {
                    'device_id': 0,
                    'trt_fp16_enable': False,
                    'trt_int8_enable': False,
                    'trt_engine_cache_enable': False
                }),
                ('CUDAExecutionProvider', {
                    'device_id': 0
                })
            ]
        elif precision == 'fp16':
            self.server_configs['providers'] = [
                ('TensorrtExecutionProvider', {
                    'device_id': 0,
                    'trt_fp16_enable': True,
                    'trt_int8_enable': False,
                    'trt_engine_cache_enable': False
                }),
                ('CUDAExecutionProvider', {
                    'device_id': 0
                })
            ]
        elif precision == 'int8':
            self.server_configs['providers'] = [
                ('TensorrtExecutionProvider', {
                    'device_id': 0,
                    'trt_fp16_enable': False,
                    'trt_int8_enable': True,
                    'trt_int8_calibration_table_name': self.server_configs['CALIBRATION'],
                    'trt_engine_cache_enable': False
                }),
                ('CUDAExecutionProvider', {
                    'device_id': 0
                })
            ]
        else:
            raise AssertionError(f"Incorrect precision environmental variable, got {self.server_configs['PRECISION']}")

        # Configure session options for ONNX Runtime
        sess_opt = ort.SessionOptions()
        sess_opt.graph_optimization_level = ort.GraphOptimizationLevel.ORT_DISABLE_ALL
        sess_opt.log_severity_level = 3

        # Create the ONNX Runtime inference session
        self.sess = ort.InferenceSession(path_or_bytes=self.server_configs['MODEL_PATH'], sess_options=sess_opt, providers=self.server_configs['providers'])

        # Store input name and shape in server configurations
        self.server_configs['input_name'] = self.sess.get_inputs()[0].name
        self.server_configs['input_shape'] = self.sess.get_inputs()[0].shape

        # Log details for debugging
        self.log(f"Providers: {self.sess.get_providers()}")
        self.log(f"Provider Options: {self.sess.get_provider_options()}")
        self.log(f"Session Options: {self.sess.get_session_options()}")
        self.log(f"Input Name: {self.server_configs['input_name']}")
        self.log(f"Input Shape: {self.server_configs['input_shape']}")

        end = time.perf_counter()
        self.once_timings['init'] = end - start
        self.log(f"Initialize time: {self.once_timings['init'] * 1000:.2f} ms")
    
    def warm_up(self):
        """
        Run first-time AI-framework/platform pair-specific server operations.
        Warm up the ONNX Runtime inference session by running a dummy input.
        """
        start = time.perf_counter()

        # Create a dummy input tensor filled with zeros
        x_dummy = tf.zeros(shape=self.server_configs['input_shape'], dtype=tf.float32).numpy()

        # Run the dummy input through the ONNX Runtime session
        _ = self.sess.run([], {self.server_configs['input_name']: x_dummy})

        end = time.perf_counter()
        self.once_timings['warm_up'] = end - start
        self.log(f"Warmup time: {self.once_timings['warm_up'] * 1000:.2f} ms")

    def experiment_single(self, input, run_total=1):
        """
        Execute the experiment for single input data.
        Works only in Latency Server Mode (self.server_configs['SERVER_MODE'] == 0).
        Takes a numpy array as input and returns a numpy array as output.
        """
        exp_output = self.sess.run([], {self.server_configs['input_name']: input})[0]
        return exp_output

    def experiment_multiple(self, dataset, run_total):
        """
        Execute the experiment for multiple input data.
        Works only in Throughput Server Mode (self.server_configs['SERVER_MODE'] == 1).
        Takes a tf.data.Dataset as input and returns a numpy array as output.
        """
        output_list = []
        iterations = run_total // self.server_configs['BATCH_SIZE']
        remainder_iteration = 1 if iterations * self.server_configs['BATCH_SIZE'] != run_total else 0

        # Iterate through the dataset, batching data and feeding it to the model
        for i, element in enumerate(dataset.take(iterations + remainder_iteration)):
            x_test = element
            if i == iterations:  # Process any remainder data in the last iteration
                x_input = tf.zeros(shape=self.server_configs['input_shape'])
                x_input_list = tf.unstack(x_input)
                x_input_list[0:x_test.shape[0]] = x_test[:]
                x_input = tf.stack(x_input_list).numpy()
            else:
                x_input = x_test.numpy()

            # Run the model and append results to output list
            output_data = self.sess.run([], {self.server_configs['input_name']: x_input})[0]
            valid_outputs = x_test.shape[0] if i == iterations else self.server_configs['BATCH_SIZE']
            output_list.append(output_data[0:valid_outputs, :])

        # Concatenate all individual outputs to form a single numpy array
        concat_start = time.perf_counter()
        exp_output = np.concatenate(output_list, axis=0)
        concat_end = time.perf_counter()

        self.log(f"Concat output time: {(concat_end - concat_start) * 1000:.2f} ms")
        return exp_output

    def platform_preprocess(self, data):
        """Preprocess the input, specific to the platform requirement, not the experiment ones. Used in create_and_preprocess as the last step."""
        return data

    def platform_postprocess(self, data):
        """Postprocess the output, specific to the platform requirement, not the experiment ones. Used in postprocess as the first step."""
        return data
