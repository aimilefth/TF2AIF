"""
Author: Aimilios Leftheriotis
Affiliations: Microlab@NTUA, VLSILab@UPatras

This script automates the process of running multiple inference requests and collecting performance metrics from an AI server. It ensures that the client can send requests, retrieve metrics, and handle retries, storing the output in a structured format.

Overview:
- The script repeatedly sends inference requests to a server.
- Collects performance metrics after a defined number of requests.
- Stores the collected metrics and logs in a specified directory with a unique identifier.

Environment Variables:
- NUMBER_OF_REQUESTS: Number of requests to send for inference.
- CLIENT_APP: Path to the client application script.
- SERVER_IP: IP address of the server.
- SERVER_PORT: Port number of the server.
- MOUNTED_DIR: Directory where the output files will be stored.
- METRICS_OUTPUT: Path to the metrics output file.
- LOG_FILE: Path to the log file.

Methods:
- add_num_threads_to_instance_UID(instance_uid, metrics_data): Appends the number of threads to the instance UID.
- check_output_format(output): Validates the output format of the inference request.
- main(): Main function to execute the script.

DO NOT edit this file directly.
"""

import os
import subprocess
import sys
import json
import shutil
import time

def add_num_threads_to_instance_UID(instance_uid, metrics_data):
    """
    Appends the number of threads to the instance UID if the 'NUM_THREADS' key is present in the metrics data.

    Args:
        instance_uid (str): The unique identifier for the instance.
        metrics_data (list): List of dictionaries containing metrics data.

    Returns:
        str: The modified instance UID with the number of threads appended.
    """
    if 'NUM_THREADS' in metrics_data[-1]:
        num_threads = metrics_data[-1]['NUM_THREADS']
        print(f"'NUM_THREADS' exists with value: {num_threads}")
        uid_parts = instance_uid.split(':')
        uid_parts[3] += f"_{num_threads}"
        instance_uid = ':'.join(uid_parts)
    return instance_uid

def check_output_format(output):
    """
    Validates the format of the output to ensure it contains the expected metrics.

    Args:
        output (str): The output string to validate.

    Returns:
        bool: True if the output format is correct, False otherwise.
    """
    lines = output.strip().split("\n")  # Split the output into lines
    if len(lines) < 2:  # There must be at least 2 lines to check
        return False
    correct_bool = lines[-2].startswith("E2E Latency") and lines[-1].startswith("Throughput")
    if correct_bool:
        print(output)
    else:
        print('The request was not completed')
    return correct_bool

def main():
    """
    Main function to execute the script. Sends inference requests, collects metrics, and stores the output files.
    """
    # Check if all required environment variables are set
    required_vars = ['NUMBER_OF_REQUESTS', 'CLIENT_APP', 'SERVER_IP', 'SERVER_PORT', 'MOUNTED_DIR', 'METRICS_OUTPUT', 'LOG_FILE']
    for var in required_vars:
        if var not in os.environ:
            sys.exit(f"Error: The environment variable {var} is not set.")

    NUMBER_OF_REQUESTS = int(os.environ['NUMBER_OF_REQUESTS'])
    CLIENT_APP = os.environ['CLIENT_APP']
    SERVER_IP = os.environ['SERVER_IP']
    SERVER_PORT = os.environ['SERVER_PORT']
    MOUNTED_DIR = os.environ['MOUNTED_DIR']
    METRICS_OUTPUT = os.environ['METRICS_OUTPUT']
    LOG_FILE = os.environ['LOG_FILE']

    # Run the get inference command for ${NUMBER_OF_REQUESTS} times
    for _ in range(NUMBER_OF_REQUESTS):
        result = subprocess.run(["python3", CLIENT_APP], stdout=subprocess.PIPE, text=True)
        while not check_output_format(result.stdout):
            time.sleep(2)
            result = subprocess.run(["python3", CLIENT_APP], stdout=subprocess.PIPE, text=True)

    # Run the get metrics command
    subprocess.run(["python3", CLIENT_APP, "-m", "True", "-n", str(NUMBER_OF_REQUESTS)])
    
    # Load the metrics.json file
    try:
        with open(METRICS_OUTPUT, 'r') as f:
            metrics_data = json.load(f)
    except FileNotFoundError:
        sys.exit(f"Error: File {METRICS_OUTPUT} not found.")

    # Get the instance_UID from the first JSON object
    instance_uid = metrics_data[0].get('instance_UID')
    if not instance_uid:
        sys.exit("Error: instance_UID not found in the first JSON object.")
    
    instance_uid = add_num_threads_to_instance_UID(instance_uid, metrics_data)
    
    # Copy the files to the mounted directory with the new name
    shutil.copy(METRICS_OUTPUT, os.path.join(MOUNTED_DIR, f'{instance_uid}.json'))
    shutil.copy(LOG_FILE, os.path.join(MOUNTED_DIR, f'{instance_uid}.log'))
    
    # Change the permissions of the files to full permissions (read, write, execute for owner, group, others)
    os.chmod(os.path.join(MOUNTED_DIR, f'{instance_uid}.json'), 0o777)
    os.chmod(os.path.join(MOUNTED_DIR, f'{instance_uid}.log'), 0o777)

if __name__ == '__main__':
    main()
